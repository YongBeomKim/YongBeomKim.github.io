---
layout: blog
title: (Docker) OPENCODE 설치 및 기초
tags:
- opencode
---

앞에서 `Ollama` 등으로 실행중인 LLM 모델을 `VsCode` 의 Extension 을 활용하여 응용하는 내용에 대하여 살펴보았습니다. 이번에는 Linux CLI 환경에서 자유롭게 모델을 활용 가능한 opencode 에 대하여 살펴보겠습니다. Ubuntu 24 환경을 기준으로 진행하겠습니다.

<br/>

# Quick Start
## Install
[opencode](https://opencode.ai/download) 공식문서에서 설치 페이지를 방문합니다. 자신에게 적합한 운영체계 방식으로 설치작업을 진행합니다.
```bash
$ curl -fsSL https://opencode.ai/install | bash
$ cd /Coding/NewProject/
$ opencode
```

`Project Root` 폴더에서 `opencode` 를 실행하면 아래와 같이 작업환경이 실행되는 것을 볼 수 있습니다. 처음에는 연결된 모델이 없어서 LLM 작업에 활용할 모델을 Connect 해야 합니다.

<figure class="align-center">
  <p style="text-align: center">
  <img width="450px" src="{{site.baseurl}}/assets/llm/opencode_connect.gif">
  </p>
</figure>

2026-01-12 기준으로 [GLM 4.7 | glm-4.7-free](https://opencode.ai/docs/zen/#endpoints) 모델을 무료로 사용 가능하도록 공개를 하고 있습니다. 무료로 공개되고 있지만 일시적으로 공개를 하고 있고, 민감정보를 유출할 가능성도 있어서 사용에 주의를 하여야 합니다.

이처럼 사용자가 모델에 대한 설정을 완료하면 작업 준비가 완료되었습니다. 프로젝트 폴더에서 `Plan \ Build` 모드를 선택한 뒤 적합한 모델을 선택하고 프롬프트를 입력하면 됩니다. 

<figure class="align-center">
  <p style="text-align: center">
  <img width="450px" src="{{site.baseurl}}/assets/llm/opencode_models.gif">
  </p>
</figure>

## Setting Files
`OPENCODE` 의 기본 설정값은 다음과 같이 확인할 수 있습니다.
```json
$ cat ~/.config/opencode/package.json  
{
  "dependencies": {
    "@opencode-ai/plugin": "1.1.15"
  }
}
```

`LLM 모델`에 대한 설정과 `API Key 값`은 다음과 같이 확인할 수 있습니다.
```json
$ cat ~/.local/share/opencode/auth.json                 
{
  "google": {
    "type": "api",
    "key": "AI....."
  },
  "groq": {
    "type": "api",
    "key": "AI....."
  },
  "opencode": {
    "type": "api",
    "key": "sk-abcd...."
  },
  "zai-coding-plan": {
    "type": "api",
    "key": "1234...."
  }
}
```

## Ollama Connect
[Easy OLLAMA Setup with OpenCode in MINUTES](https://youtu.be/RIvM-8Wg640) 를 참고하여 `On-Premise` 에서 작동중인 `Ollama` 를 활용하는 방법에 대하여 살펴보겠습니다.


[OPENCODE - providers](https://opencode.ai/docs/providers/#ollama) 공식문서에서 제공하는 ollama 설정내용은 다음과 같습니다. `opencode.json` 를 프로젝트 폴더의 `root` 에 생성하면 프로젝트 단위로 다르게 적용할 수 있습니다.
```json
$ nvim ~/.config/opencode/opencode.json
{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "ollama": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Ollama (local)",
      "options": {
        "baseURL": "http://localhost:11434/v1"
      },
      "models": {
        "hf.co/TeichAI/Qwen3-8B-DeepSeek-v3.2-Speciale-Distill-GGUF:Q4_K_M": {
          "name": "Deepseek v3.2"
        }
      }
    }
  }
}
```
