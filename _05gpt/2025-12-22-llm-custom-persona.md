---
layout: blog
title: LLM Persona 생성 및 활용
tags:
- ollama
---

`LLM` 작업을 하다보면 `반복적으로 재활용하는 Prompt`가 있습니다. 이러한 작업을 보다 효과적으로 실행하는 내용에 대하여 살펴보겠습니다.

<br/>

# GGUP Models
[Ollama Library](https://ollama.com/library) 에서 바로 제공하는 모델을 사용하는 방법이 있습니다. 보다 다양한 모델들을 [Huggingface models](https://huggingface.co/models) 에서 확인할 수 있습니다. 개발자가 관심있는 목록을 확인하고 해당 개별 모델의 페이지에 접속하면 `Use this model` 버튼을 눌러서 `Ollama` 버튼 활성화 하는지 확인하면 됩니다.

[Qwen3-14B-claude-sonnet-4.5-high-reasoning-distill-Q4_K_M.gguf](https://huggingface.co/TeichAI/Qwen3-14B-Claude-Sonnet-4.5-Reasoning-Distill-GGUF) 에서 보이는 것처럼 `Q3_K_M.gguf` 에서 **Q 뒤의 숫자와 K, M** 은 **GGUF 양자화(quantization) 방식** 을 의미합니다. GGUF는 대형 언어 모델을 더 작은 메모리와 빠른 속도로 실행할 수 있도록 가중치를 압축하는 포맷을 의미합니다.  

## `Q` 뒤의 숫자 의미
- `Q3`, `Q4`, `Q5` … → **양자화 비트 수**를 의미합니다.  
- `Q3` → 3비트 양자화 (더 작은 메모리, 더 빠른 속도, 하지만 정확도 손실이 큼)  
- `Q4` → 4비트 양자화 (균형형: 속도와 정확도 사이에서 가장 많이 쓰임)  
- `Q5`, `Q6` → 더 높은 비트수, 메모리 사용량은 늘지만 정확도는 원본에 더 가까움  

## `K, M` 등의 접미사 의미
GGUF에서는 같은 비트수라도 **양자화 방식**이 여러 가지 있습니다.  
- **K** → *grouped quantization* (그룹 단위로 최적화, 속도와 정확도 균형)  
- **M** → *mixed quantization* (가중치 종류별로 다른 비트수를 섞어 사용, 성능 최적화)  
- **S, L, F** 등 다른 접미사도 존재하며, 각각 메모리 효율과 정확도 특성이 다름  

위의 내용들을 종합하여 구제적인 예들을 살펴보면 다음과 같습니다
- `Q4_K_M` → 4비트 양자화, K 방식 + M 변형을 적용한 버전 (**속도와 정확도의 균형이 좋아서 대부분 추천되는 선택지**)
- `Q3_K_M` → 3비트 양자화, 같은 방식이지만 더 압축됨 (**가볍고 빠르지만 정확도 손실이 크다**)

## ⚖️ 성능 차이 요약
| 모델 버전 | 메모리 사용량 | 속도 | 정확도(추론 성능) |
|-----------|---------------|------|------------------|
| **Q3_K_M** | 가장 적음 (RAM/GPU VRAM 절약) | 가장 빠름 | 정확도 손실 큼, 긴 문맥/복잡한 추론에서 오류 가능성 ↑ |
| **Q4_K_M** | 중간 (보통 권장) | 빠름 | 정확도와 속도 균형, 실사용에 가장 적합 |
| **Q5 이상** | 많음 | 느려짐 | 원본 모델에 더 가까운 정확도 |

<br/>

# Docker in Ollama
## 기본적인 스크립트를 사용자 ollama 모델에 추가하기
```bash
FROM freehuntx/qwen3-coder:8b

# task.md의 내용을 여기에 복사하여 시스템 프롬프트로 설정
SYSTEM """
당신은 숙련된 시니어 소프트웨어 엔지니어입니다. 
다음 파일의 코드를 분석하고 리뷰를 작성해주세요.

1. 목적: 코드 품질 향상, 버그 발견, 유지보수성 개선.
2. 리뷰 항목:
   - 효율성: 시간/공간 복잡도 및 리소스 최적화.
   - 안정성: 잠재적 버그, 예외 처리, 보안 취약점.
   - 가독성: 변수 명명, 함수 분리, 클린 코드 원칙.
   - 언어 특성: Python(PEP8), React/TS(Hooks 규칙, Type 안정성) 준수 여부.
3. 형식: 
   - 결과는 반드시 마크다운(Markdown)으로 출력하세요.
   - 설명은 명확하고 친절한 한국어로 작성하세요.
   - 개선이 필요한 부분은 반드시 '개선 예시 코드'를 포함하세요.
"""
# 창의성 조절 (코드 리뷰이므로 낮게 설정)
PARAMETER temperature 0.2
```

## 정의한 사용자 Ollama 모델 빌드하기
```bash
ollama create code-review -f Modelfile
```
