---
layout: blog
title: Numpy 60줄로 구현하는 GPT
tags:
- gpt
---

이전에 [트랜트포머를 활용한 자연어 처리](https://yongbeomkim.github.io/contents/huggingface) 를 리뷰하면서, 좋았던 점은 볶잡한 모델들을 손쉽게 다룰 수 있어서 좋았습니다. 하지만 공개된 대부분의 모델들이 `네이버 영화리뷰` 등의 데이터를 기반으로 학습이 되어 있어서 특정분야에 맞는 결과물을 도출하기 까지는 어려움이 있었습니다.

따라서 간단한 내용이라도 내가 학습데이터를 생성할 수 있었으면 좋겠다는 필요를 느끼게 되었고, 검색을 하다가 찾은 내용이 Numpy 를 활용한 GPT 구현이었습니다. 이번 내용을 학습한 뒤 [Let's build GPT: from scratch, in code, spelled out.](https://youtu.be/kCc8FmEb1nY) 그리고 [NLP: Implementing BERT and Transformers from Scratch](https://www.youtube.com/watch?v=EPa98fyxZ-s&t=8166s) 까지 단계적으로 진행해 보겠습니다.

우선 첫번째로 다뤄볼 내용은 [GPT-2 from scratch in just 60 lines of numpy](https://jaykmody.com/blog/gpt-from-scratch/) 입니다. 소스코드는 [picoGPT - Github](https://github.com/jaymody/picoGPT) 에서 살펴볼 수 있습니다.

<figure class="align-center">
  <p style="text-align: center">
  <iframe width="560" height="315" 
    src="https://www.youtube.com/embed/8NCL03ZKNxY" 
    title="YouTube video player" frameborder="0" 
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
    allowfullscreen
  ></iframe>
  </p>
  <figcaption>Making SimpleGPT2</figcaption>
</figure>

<br/>

# 참고사이트
- [PyTorch of GPT](https://youtu.be/d7IRM40VMYM)
- [Mastering BERT Model: Building it from Scratch with Pytorch](https://medium.com/data-and-beyond/complete-guide-to-building-bert-model-from-sratch-3e6562228891)
- [DataScience with Pytorch | GitHub ](https://github.com/ChanCheeKean/DataScience/tree/main/13%20-%20NLP)
- [Neural Networks: Zero to Hero](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
- [Training BERT](https://www.youtube.com/playlist?list=PLIUOU7oqGTLgQ7tCdDT0ARlRoh1127NSO)
- [Natural Language Processing Demystified](https://www.youtube.com/playlist?list=PLw3N0OFSAYSEC_XokEcX8uzJmEZSoNGuS)

```html
<figure class="align-center">
  <img width="450px" src="{{site.baseurl}}/assets/book/better_front.jpg">
  <figcaption>더 나은 웹 개발을 위한 가이드</figcaption>
</figure>
```
